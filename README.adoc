= Lab 13 - Running Applications in Kubernetes
:tip-caption: ðŸ’¡ TIP
:warning-caption: âš ï¸ WARNING

> *Challenge: Can you run the pharmacy application within your Kubernetes cluster?*

We will use K3s, a lightweight, easy-to-install Kubernetes distribution designed for local development and testing.

== 1. Setting Up the K3s Cluster

=== Install K3s

We install K3s as a system service. (Be patience, this process takes some minutes.)

[source,shell]
----
$ curl -sfL https://get.k3s.io | sh -
----

The k3s server can be reviewed and managed with the following commands:

[source,shell]
----
$ sudo systemctl status k3s.service
$ sudo systemctl start k3s.service
$ sudo systemctl stop k3s.service
----

NOTE: A `kubeconfig` file is written to `/etc/rancher/k3s/k3s.yaml`. The service is automatically started, and utilities like `kubectl` are installed.

=== Verify Cluster Status

Use `kubectl` (aliased via `sudo` because of the installation path) to verify the node is ready.

[source,shell]
----
$ sudo kubectl get nodes
NAME              STATUS   ROLES                 AGE   VERSION
fedora.home.lab   Ready    control-plane,master  26s   v1.33.5+k3s1
----

List all the default namespaces in the cluster before adding ours; these namespaces are used for the cluster configuration and we should not modify them.

[source,shell]
----
$ sudo kubectl get namespaces
NAME              STATUS   AGE
default           Active   2m21s
kube-node-lease   Active   2m21s
kube-public       Active   2m21s
kube-system       Active   2m21s
----

=== Create Namespace

Namespaces provide logical isolation within the Kubernetes cluster.

[source,shell]
----
$ sudo kubectl apply -f namespace.yml
----

== 2. Defining the Application Deployment (8 Manifests)

The application stack requires eight separate YAML manifests to define persistence, networking, security, and deployment units.

=== Apply Persistence and Network Policy

We first apply the security and storage infrastructure.

[source,shell]
----
# 1. Apply Persistent Volume Claim (Required by order-service for /data persistence)
$ sudo kubectl apply -f volumeclaim.yml

# 2. Apply Network Policy (CRITICAL: Enforces internal communication and denies external access)
$ sudo kubectl apply -f networkpolicy.yml
----

=== Apply Deployment and Service Manifests

We apply the core application components.

[source,shell]
----
# 1. Apply Deployments (Creates the Pods and sets resource limits/security context)
$ sudo kubectl apply -f deployment.yml

# 2. Apply Internal ClusterIP Services (Enables internal DNS resolution: order-service -> inventory-service)
$ sudo kubectl apply -f service.yml
----

== 3. Troubleshooting Image Access

=== Encountering the ImagePullBackOff Error

Check the status of the pods:

[source,shell]
----
$ sudo kubectl get pods -n pharmacy
NAME                 READY   STATUS             RESTARTS   AGE
billing-...          0/1     ImagePullBackOff   0          3h7m
----

ðŸ’¡ TIP: The `ImagePullBackOff` error occurs because K3s (using ContainerD) cannot access the local Podman image repository (`localhost/pharmacy:latest`). It needs the image loaded into its own internal registry.

=== Export Image from Podman

We save the local image into a `tar` archive that can be exported.

[source,shell]
----
$ podman save -o pharmacy.tar localhost/pharmacy:latest

$ ls -l pharmacy.tar
-rw-r--r--. 1 username username 480112640 Jan 15 12:56 pharmacy.tar
----

=== Import Image into ContainerD

We use the `ctr` (ContainerD) tool to load the image archive directly into the K3s internal repository.

[source,shell]
----
$ sudo ctr -n k8s.io image import pharmacy.tar
unpacking localhost/pharmacy:latest...done
----

We can verify the image is now visible to K3s's runtime using `crictl`:

[source,shell]
----
$ sudo crictl images | grep pharmacy
localhost/pharmacy               latest             1151dc4cf1d4a       480MB
----

== 4. Final Deployment and Access

=== Redeploy the Manifest

Applying the deployment YAML again forces the scheduler to restart the pods. Since the image is now locally available, the pods will successfully enter the `Running` state.

[source,shell]
----
# We delete the failed resources and reapply them to force a clean pull attempt
$ sudo kubectl delete -f deployment.yml
$ sudo kubectl apply -f deployment.yml
----

Check the status:

[source,shell]
----
$ sudo kubectl get pods -n pharmacy
NAME                 READY   STATUS    RESTARTS   AGE
billing-...          1/1     Running   0          2m
# ... (all pods should show Running)
----

=== Expose and Test External Service Access

To make the application accessible from your host machine (outside the K3s cluster), we create a service of type `NodePort` (the easiest type for local testing on K3s).

[source,shell]
----
$ sudo kubectl apply -f nodeport.yml
service/order-service-external created
----

== Test Application

Retrieve the external port assigned to your service (it should be 30002 or a port in the range 30000-32767).

[source,shell]
----
# Use the Node's IP and the NodePort (e.g., 30002) to access the Order Service externally.
$ curl http://127.0.0.1:30002/view_orders
----

== 5. Terminating the Lab

[source,shell]
----
# Delete all external services first
$ sudo kubectl delete -f nodeport.yml

# Delete all resources in the pharmacy namespace
$ sudo kubectl delete ns pharmacy

# Stop K3s cluster
$ sudo systemctl stop k3s
----

== Final Conclusion: The Journey to Containerization

The series of labs, from modeling the monolithic application (Lab 1) to deploying a complete microservices stack on K3s (Lab 13), demonstrates the fundamental shift required for modern application management.

By breaking down applications into smaller, manageable services and leveraging container orchestration platforms like Kubernetes, developers and operations teams can achieve greater scalability, resilience, and agility in deploying applications. This journey highlights the importance of understanding both the application architecture and the underlying infrastructure to fully harness the benefits of containerization.
